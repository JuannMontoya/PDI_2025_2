{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T12:12:47.303777Z","iopub.execute_input":"2025-12-12T12:12:47.304562Z","iopub.status.idle":"2025-12-12T12:12:47.309781Z","shell.execute_reply.started":"2025-12-12T12:12:47.304528Z","shell.execute_reply":"2025-12-12T12:12:47.308929Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#https://drive.google.com/file/d/1aK5SY2tKMeSPsUoyloOFHQFy3OPv9zeX/view?usp=drivesdk\n#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","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T12:12:47.311217Z","iopub.execute_input":"2025-12-12T12:12:47.311802Z","iopub.status.idle":"2025-12-12T12:12:47.327624Z","shell.execute_reply.started":"2025-12-12T12:12:47.311783Z","shell.execute_reply":"2025-12-12T12:12:47.326928Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install ultralytics -q\n!pip install gdown -q\n!pip install tensorflow -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T12:12:47.328458Z","iopub.execute_input":"2025-12-12T12:12:47.328667Z","iopub.status.idle":"2025-12-12T12:12:57.019912Z","shell.execute_reply.started":"2025-12-12T12:12:47.328649Z","shell.execute_reply":"2025-12-12T12:12:57.019035Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\nimport time\nimport gdown\nimport numpy as np\nimport pandas as pd\nfrom ultralytics import YOLO\nimport tensorflow as tf\n\nDRIVE_ID = '1aK5SY2tKMeSPsUoyloOFHQFy3OPv9zeX'\nMODEL_NAME = 'best.pt'\n\ngdown.download(f'https://drive.google.com/uc?id={DRIVE_ID}', MODEL_NAME, quiet=True)\n\nmodel = YOLO(MODEL_NAME)\nexport_path = model.export(format='tflite', half=True)\n\ntflite_path = None\nif export_path and os.path.exists(export_path):\n    tflite_path = export_path\nelse:\n    for r,_,fs in os.walk(\".\"):\n        for f in fs:\n            if f.endswith(\".tflite\"):\n                tflite_path = os.path.join(r,f)\n\nsize_pt = os.path.getsize(MODEL_NAME)/(1024*1024)\nsize_tflite = os.path.getsize(tflite_path)/(1024*1024)\n\nN = 5\nimgs = [np.random.randint(0,255,(640,640,3),dtype=np.uint8) for _ in range(N)]\n\npt_times = []\ntflite_times = []\nious = []\n\ndef iou(box1, box2):\n    x1=max(box1[0],box2[0])\n    y1=max(box1[1],box2[1])\n    x2=min(box1[2],box2[2])\n    y2=min(box1[3],box2[3])\n    inter=max(0,x2-x1)*max(0,y2-y1)\n    a1=(box1[2]-box1[0])*(box1[3]-box1[1])\n    a2=(box2[2]-box2[0])*(box2[3]-box2[1])\n    union=a1+a2-inter\n    return inter/union if union>0 else 0\n\ninterpreter = tf.lite.Interpreter(model_path=tflite_path)\ninterpreter.allocate_tensors()\ninp = interpreter.get_input_details()\noutp = interpreter.get_output_details()\n\nfor img in imgs:\n\n    t0 = time.time()\n    r_pt = model(img)[0]\n    pt_times.append((time.time()-t0)*1000)\n\n    boxes_pt = r_pt.boxes.xyxy.cpu().numpy() if r_pt.boxes is not None else None\n\n    img_f = img.astype(np.float32)[None]\n    t1 = time.time()\n    interpreter.set_tensor(inp[0]['index'], img_f)\n    interpreter.invoke()\n    out = interpreter.get_tensor(outp[0]['index'])\n    tflite_times.append((time.time()-t1)*1000)\n\n    if boxes_pt is not None and len(boxes_pt)>0 and out.shape[-1]>=4:\n        b1 = boxes_pt[0]\n        b2 = out[0][:4]\n        ious.append(iou(b1,b2))\n\navg_pt = sum(pt_times)/len(pt_times)\navg_tflite = sum(tflite_times)/len(tflite_times)\navg_iou = sum(ious)/len(ious) if len(ious)>0 else 0\n\ndf = pd.DataFrame({\n    \"MÃ©trica\":[\"TamaÃ±o (MB)\",\"Inferencia ms\",\"IoU promedio\"],\n    \"PT\":[size_pt, avg_pt, 1.0],\n    \"TFLite\":[size_tflite, avg_tflite, avg_iou]\n})\n\nprint(df.to_string(index=False))\n\nprint(\"\\nGrÃ¡fico ASCII â€” Tiempo de Inferencia\\n\")\nmx = max(avg_pt, avg_tflite)\nscale = 50/mx\n\ndef bar(v): return \"â–ˆ\" * int(v*scale)\n\nprint(f\"PT     | {bar(avg_pt)} {avg_pt:.1f} ms\")\nprint(f\"TFLite | {bar(avg_tflite)} {avg_tflite:.1f} ms\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T12:24:35.223548Z","iopub.execute_input":"2025-12-12T12:24:35.224354Z","iopub.status.idle":"2025-12-12T12:24:54.311435Z","shell.execute_reply.started":"2025-12-12T12:24:35.224318Z","shell.execute_reply":"2025-12-12T12:24:54.310663Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.236 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon CPU @ 2.00GHz)\nYOLO11n summary (fused): 100 layers, 2,587,417 parameters, 0 gradients, 6.3 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 31, 8400) (5.2 MB)\n\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.78...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.3s, saved as 'best.onnx' (10.2 MB)\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.5...\nSaved artifact at 'best_saved_model'. The following endpoints are available:\n\n* Endpoint 'serving_default'\n  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\nOutput Type:\n  TensorSpec(shape=(1, 31, 8400), dtype=tf.float32, name=None)\nCaptures:\n  136215722698192: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215722697424: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n  136215722698000: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136215722698768: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215722698384: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136215722698576: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215722698960: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n  136215722699152: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215722699728: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722699536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722700496: TensorSpec(shape=(3, 3, 16, 8), dtype=tf.float32, name=None)\n  136215722701840: TensorSpec(shape=(8,), dtype=tf.float32, name=None)\n  136215722699344: TensorSpec(shape=(3, 3, 8, 16), dtype=tf.float32, name=None)\n  136215722696272: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136215722699920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722700112: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722702032: TensorSpec(shape=(1, 1, 48, 64), dtype=tf.float32, name=None)\n  136215722702224: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722701264: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215722700688: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215722701072: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722702416: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215722702800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722703376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722703184: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722703952: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n  136215722702992: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136215722704336: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136215722704720: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215722703568: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722703760: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722704144: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n  136215722702608: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214764618576: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136214764618384: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  136214764618768: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214764618960: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136214764619344: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214764619920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214764619728: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214764620688: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n  136214764622032: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214764622416: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136214764622224: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214764619152: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136214764621456: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214764622800: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136214764622992: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214764621264: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136214764619536: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n  136214764623184: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214764620880: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214764623760: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214764623568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214764620112: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214764620304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214764623952: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136214764622608: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214764624336: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136214764624144: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n  136214764623376: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214764624528: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136214764624912: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214764625488: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214764625296: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214764626256: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136214764627600: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214764627984: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214764627792: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214764624720: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214764627024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214764628368: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214764628560: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214764626832: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214764625104: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136214764628752: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214764626448: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214764629328: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136214764629136: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214764625680: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214764625872: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214764629520: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136214764628176: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214764629712: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  136214764629904: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214764630288: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n  136214764630096: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214764630480: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136214764630672: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214764631248: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n  136214764628944: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215722693776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  136215722697040: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136216238109712: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136222337351120: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215722696080: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n  136215722695120: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215722697616: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  136215722695312: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215722696656: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136215722695504: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136216188775760: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n  136216188780176: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136216188775184: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188769232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188768464: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n  136216188779792: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136216188775568: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n  136216188770960: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136216188777296: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188775952: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188779216: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136216188771344: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136216188770768: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n  136216188768272: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910943248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910943056: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188770576: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n  136216188772112: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136216188779024: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136216188776720: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136216188774992: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910941328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910949584: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n  136215910950544: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910947088: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215910946128: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910942672: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910949968: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136215910954576: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910948048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910954384: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910950928: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n  136215910955728: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215910956496: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n  136215910949200: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910953232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910951504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910946704: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136215910953424: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910949392: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215910952848: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  136215910941136: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910946320: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136215910953808: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910941520: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910946896: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910954768: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136215910948816: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910946512: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910954000: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136216257797328: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910945936: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910945744: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215833199440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833200784: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910953040: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136215833200976: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910944784: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833200208: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136215833199632: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910956304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910953616: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833201552: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136215833200016: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215833202128: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n  136215910944976: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n  136215910951120: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136215833200592: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910952080: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910949776: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833202704: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n  136215910941904: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136215910950160: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215833200400: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910940752: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910951888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833208080: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136215833201936: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n  136215910955344: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136215910943440: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n  136215910955536: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136215910949008: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215833202320: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833201744: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910947472: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910942288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910956112: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910951312: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833210384: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215833201360: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910944400: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215910952656: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910954192: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215910950736: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215833206160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833205584: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910942096: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910944016: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910952464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910956688: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833207696: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136215833201168: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215910948432: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136215910942864: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215910950352: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136215910947856: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215833206352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833208272: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136215910948240: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910945360: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136215910955920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910951696: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136215833207888: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n  136215833206544: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136215833211344: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136215833206736: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136215833210768: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136215833213648: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n  136215833208464: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1765542289.924225     136 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1765542289.924399     136 single_machine.cc:361] Starting new session\nW0000 00:00:1765542290.739877     136 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1765542290.739913     136 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1765542291.437537     136 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1765542291.437674     136 single_machine.cc:361] Starting new session\nW0000 00:00:1765542292.190999     136 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1765542292.191042     136 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 15.1s, saved as 'best_saved_model' (25.6 MB)\n\n\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'best_saved_model/best_float16.tflite' (5.1 MB)\n\nExport complete (15.4s)\nResults saved to \u001b[1m/kaggle/working\u001b[0m\nPredict:         yolo predict task=detect model=best_saved_model/best_float16.tflite imgsz=640 half \nValidate:        yolo val task=detect model=best_saved_model/best_float16.tflite imgsz=640 data=/kaggle/working/PDI_Project-1/data.yaml half \nVisualize:       https://netron.app\n\n0: 640x640 (no detections), 108.3ms\nSpeed: 21.7ms preprocess, 108.3ms inference, 9.2ms postprocess per image at shape (1, 3, 640, 640)\n","output_type":"stream"},{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n","output_type":"stream"},{"name":"stdout","text":"\n0: 640x640 (no detections), 101.1ms\nSpeed: 2.4ms preprocess, 101.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 102.1ms\nSpeed: 2.5ms preprocess, 102.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 103.3ms\nSpeed: 2.3ms preprocess, 103.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 103.3ms\nSpeed: 2.5ms preprocess, 103.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n      MÃ©trica         PT     TFLite\n  TamaÃ±o (MB)   5.245807   5.128023\nInferencia ms 121.955681 129.680729\n IoU promedio   1.000000   0.000000\n\nGrÃ¡fico ASCII â€” Tiempo de Inferencia\n\nPT     | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 122.0 ms\nTFLite | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 129.7 ms\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import os\nimport time\nimport gdown\nimport numpy as np\nimport pandas as pd\nfrom ultralytics import YOLO\nimport tensorflow as tf\nimport plotly.graph_objects as go\n\nDRIVE_ID = '1aK5SY2tKMeSPsUoyloOFHQFy3OPv9zeX'\nMODEL_NAME = 'best.pt'\n\ngdown.download(f'https://drive.google.com/uc?id={DRIVE_ID}', MODEL_NAME, quiet=True)\n\nmodel = YOLO(MODEL_NAME)\nexport_path = model.export(format='tflite', half=True)\n\ntflite_path = None\nif export_path and os.path.exists(export_path):\n    tflite_path = export_path\nelse:\n    for r,_,fs in os.walk(\".\"):\n        for f in fs:\n            if f.endswith(\".tflite\"):\n                tflite_path = os.path.join(r,f)\n\nsize_pt = os.path.getsize(MODEL_NAME)/(1024*1024)\nsize_tflite = os.path.getsize(tflite_path)/(1024*1024)\n\nN = 5\nimgs = [np.random.randint(0,255,(640,640,3),dtype=np.uint8) for _ in range(N)]\n\npt_times = []\ntflite_times = []\nious = []\n\ndef iou(box1, box2):\n    x1=max(box1[0],box2[0])\n    y1=max(box1[1],box2[1])\n    x2=min(box1[2],box2[2])\n    y2=min(box1[3],box2[3])\n    inter=max(0,x2-x1)*max(0,y2-y1)\n    a1=(box1[2]-box1[0])*(box1[3]-box1[1])\n    a2=(box2[2]-box2[0])*(box2[3]-box2[1])\n    union=a1+a2-inter\n    return inter/union if union>0 else 0\n\ninterpreter = tf.lite.Interpreter(model_path=tflite_path)\ninterpreter.allocate_tensors()\ninp = interpreter.get_input_details()\noutp = interpreter.get_output_details()\n\nfor img in imgs:\n    t0 = time.time()\n    r_pt = model(img)[0]\n    pt_times.append((time.time()-t0)*1000)\n\n    boxes_pt = r_pt.boxes.xyxy.cpu().numpy() if r_pt.boxes is not None else None\n\n    img_f = img.astype(np.float32)[None]\n    t1 = time.time()\n    interpreter.set_tensor(inp[0]['index'], img_f)\n    interpreter.invoke()\n    out = interpreter.get_tensor(outp[0]['index'])\n    tflite_times.append((time.time()-t1)*1000)\n\n    if boxes_pt is not None and len(boxes_pt)>0 and out.shape[-1]>=4:\n        b1 = boxes_pt[0]\n        b2 = out[0][:4]\n        ious.append(iou(b1,b2))\n\navg_pt = sum(pt_times)/len(pt_times)\navg_tflite = sum(tflite_times)/len(tflite_times)\navg_iou = sum(ious)/len(ious) if len(ious)>0 else 0\n\ndf = pd.DataFrame({\n    \"MÃ©trica\":[\"TamaÃ±o (MB)\",\"Inferencia ms\",\"IoU promedio\"],\n    \"PT\":[size_pt, avg_pt, 1.0],\n    \"TFLite\":[size_tflite, avg_tflite, avg_iou]\n})\n\nprint(df.to_string(index=False))\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df[\"MÃ©trica\"], y=df[\"PT\"], name=\"PT\"))\nfig.add_trace(go.Bar(x=df[\"MÃ©trica\"], y=df[\"TFLite\"], name=\"TFLite\"))\nfig.update_layout(title=\"ComparaciÃ³n PT vs TFLite\", barmode='group', yaxis_title=\"Valor\")\nfig.show()\n\nfig_time = go.Figure()\nfig_time.add_trace(go.Bar(x=[\"PT\", \"TFLite\"], y=[avg_pt, avg_tflite]))\nfig_time.update_layout(title=\"Tiempo de Inferencia (ms)\", yaxis_title=\"ms\")\nfig_time.show()\n\nmetrics = [\"TamaÃ±o\", \"Inferencia\", \"IoU\"]\npt_norm = np.array([\n    size_pt / max(size_pt, size_tflite),\n    avg_pt / max(avg_pt, avg_tflite),\n    1.0\n])\ntflite_norm = np.array([\n    size_tflite / max(size_pt, size_tflite),\n    avg_tflite / max(avg_pt, avg_tflite),\n    avg_iou\n])\n\nfig_radar = go.Figure()\nfig_radar.add_trace(go.Scatterpolar(r=pt_norm, theta=metrics, fill='toself', name='PT'))\nfig_radar.add_trace(go.Scatterpolar(r=tflite_norm, theta=metrics, fill='toself', name='TFLite'))\nfig_radar.update_layout(title=\"Radar â€” PT vs TFLite\", polar=dict(radialaxis=dict(visible=True, range=[0,1])), showlegend=True)\nfig_radar.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T12:28:27.400236Z","iopub.execute_input":"2025-12-12T12:28:27.401026Z","iopub.status.idle":"2025-12-12T12:28:51.435041Z","shell.execute_reply.started":"2025-12-12T12:28:27.401001Z","shell.execute_reply":"2025-12-12T12:28:51.434329Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.236 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon CPU @ 2.00GHz)\nYOLO11n summary (fused): 100 layers, 2,587,417 parameters, 0 gradients, 6.3 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 31, 8400) (5.2 MB)\n\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.78...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.3s, saved as 'best.onnx' (10.2 MB)\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.5...\nSaved artifact at 'best_saved_model'. The following endpoints are available:\n\n* Endpoint 'serving_default'\n  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\nOutput Type:\n  TensorSpec(shape=(1, 31, 8400), dtype=tf.float32, name=None)\nCaptures:\n  136215833214224: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215833214416: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n  136215833210960: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136215833213456: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215833214800: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136215833212880: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215833212688: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n  136215833210000: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215833200784: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833199440: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833201552: TensorSpec(shape=(3, 3, 16, 8), dtype=tf.float32, name=None)\n  136215833201936: TensorSpec(shape=(8,), dtype=tf.float32, name=None)\n  136215833212304: TensorSpec(shape=(3, 3, 8, 16), dtype=tf.float32, name=None)\n  136215833207312: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136215833200976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833200208: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833202320: TensorSpec(shape=(1, 1, 48, 64), dtype=tf.float32, name=None)\n  136215833201744: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833202704: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215833200016: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215833200592: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833210384: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215833206160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215833201168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833207696: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833206544: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n  136215833210576: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136215833205584: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136215833201360: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215833206352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833208272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215833207504: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n  136215833205776: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215833213648: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215833211344: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  136215833210768: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215833207120: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136215833208656: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910949584: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910941328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910942672: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n  136215910956496: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215910953232: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136215910949200: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215910943056: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136215910954384: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215910946704: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136215910953424: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215910948048: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136215910943248: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n  136215910949392: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215910949968: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215910946320: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215910941136: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910950544: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910947088: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910953808: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136215910951504: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910946896: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215910941520: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n  136215910952848: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910954768: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136215910946512: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910945744: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910945936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910953616: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136215910940752: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910955344: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910951888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910948816: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910949776: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910955536: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910949008: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910952080: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215910954000: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136215910947472: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910944976: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910951312: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136215910956112: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910953040: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910944784: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910944400: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136215910943440: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910952656: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  136215910954192: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910942096: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n  136215910950736: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910944016: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136215910952464: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910942864: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n  136215910942288: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910945168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  136215910948432: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910955920: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136215910952272: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910945552: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n  136215910954960: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910944208: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  136215910947664: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215910948240: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136215910955152: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215910947280: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n  136215910941712: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136216188769232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188779792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215910951696: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n  136215910950352: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215910948624: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n  136215910956688: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215910940944: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188775760: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188779216: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136216188771344: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136216188775952: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n  136216188775568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136216188770576: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188768272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188777488: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n  136216188770768: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136216188780368: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136216188776144: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136216188772112: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188779024: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136216188774992: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n  136216188775184: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722698000: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215722697424: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215722698768: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722699344: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136215722696272: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215722702032: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722701072: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722702608: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n  136215722700688: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136215722697040: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n  136215722693776: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722702800: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722703376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215722696656: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136215722695504: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215722704528: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215722701648: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  136215722695312: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215722695696: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136215722700304: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215903989840: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215903985232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215903993104: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136215903988880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215903984848: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215903991184: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215709551696: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215709549200: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215709549008: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215709555920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215709551312: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215903992912: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136215709548816: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215903979088: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215709550160: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136215709553808: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215903983696: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215903980432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136215709550352: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136215709554000: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215709549392: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n  136215722697232: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n  136215722699728: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136215709549776: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136215722697616: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136215722698960: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215709549968: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n  136215722701456: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136215722700496: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215909072720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722697808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722699152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215909070800: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136215709551504: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n  136215903988304: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136215722703568: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n  136215722701264: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136215722698384: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215909071952: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215709560720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215903987920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722700880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722699920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722698576: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215909072336: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215709552080: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215903984272: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215722696080: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136215722702992: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215722699536: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136221758998480: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215709552656: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215903985040: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722695120: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722703952: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722701840: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136221758998672: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136215909071568: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215903993296: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136215903986192: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215722702416: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136215722702224: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136215909072528: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136221758998864: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136215903990992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215709559952: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136215722700112: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136215722704720: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136216273796752: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n  136221758999248: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136221759000016: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136221758999632: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136221758998288: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136221759000208: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n  136221758997904: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1765542525.174057     136 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1765542525.174223     136 single_machine.cc:361] Starting new session\nW0000 00:00:1765542526.007270     136 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1765542526.007316     136 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1765542526.708285     136 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1765542526.708458     136 single_machine.cc:361] Starting new session\nW0000 00:00:1765542527.413138     136 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1765542527.413173     136 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 15.3s, saved as 'best_saved_model' (25.6 MB)\n\n\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'best_saved_model/best_float16.tflite' (5.1 MB)\n\nExport complete (15.6s)\nResults saved to \u001b[1m/kaggle/working\u001b[0m\nPredict:         yolo predict task=detect model=best_saved_model/best_float16.tflite imgsz=640 half \nValidate:        yolo val task=detect model=best_saved_model/best_float16.tflite imgsz=640 data=/kaggle/working/PDI_Project-1/data.yaml half \nVisualize:       https://netron.app\n\n0: 640x640 (no detections), 121.0ms\nSpeed: 3.4ms preprocess, 121.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 104.3ms\nSpeed: 2.6ms preprocess, 104.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 107.2ms\nSpeed: 2.4ms preprocess, 107.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 104.5ms\nSpeed: 2.3ms preprocess, 104.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 104.1ms\nSpeed: 2.5ms preprocess, 104.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n      MÃ©trica         PT     TFLite\n  TamaÃ±o (MB)   5.245807   5.128061\nInferencia ms 122.100973 129.834127\n IoU promedio   1.000000   0.000000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"03b5d87c-d722-47aa-b9fd-8803e0c28bb5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"03b5d87c-d722-47aa-b9fd-8803e0c28bb5\")) {                    Plotly.newPlot(                        \"03b5d87c-d722-47aa-b9fd-8803e0c28bb5\",                        [{\"name\":\"PT\",\"x\":[\"TamaÃ±o (MB)\",\"Inferencia ms\",\"IoU promedio\"],\"y\":[5.245806694030762,122.10097312927246,1.0],\"type\":\"bar\"},{\"name\":\"TFLite\",\"x\":[\"TamaÃ±o (MB)\",\"Inferencia ms\",\"IoU promedio\"],\"y\":[5.128061294555664,129.83412742614746,0.0],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"ComparaciÃ³n PT vs TFLite\"},\"barmode\":\"group\",\"yaxis\":{\"title\":{\"text\":\"Valor\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('03b5d87c-d722-47aa-b9fd-8803e0c28bb5');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"dc7344dd-926e-4bce-84d0-c494790691a7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dc7344dd-926e-4bce-84d0-c494790691a7\")) {                    Plotly.newPlot(                        \"dc7344dd-926e-4bce-84d0-c494790691a7\",                        [{\"x\":[\"PT\",\"TFLite\"],\"y\":[122.10097312927246,129.83412742614746],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Tiempo de Inferencia (ms)\"},\"yaxis\":{\"title\":{\"text\":\"ms\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('dc7344dd-926e-4bce-84d0-c494790691a7');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"eee571da-c4a2-439f-b32d-15c65143fa9e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eee571da-c4a2-439f-b32d-15c65143fa9e\")) {                    Plotly.newPlot(                        \"eee571da-c4a2-439f-b32d-15c65143fa9e\",                        [{\"fill\":\"toself\",\"name\":\"PT\",\"r\":[1.0,0.9404382002623016,1.0],\"theta\":[\"TamaÃ±o\",\"Inferencia\",\"IoU\"],\"type\":\"scatterpolar\"},{\"fill\":\"toself\",\"name\":\"TFLite\",\"r\":[0.9775543769828421,1.0,0.0],\"theta\":[\"TamaÃ±o\",\"Inferencia\",\"IoU\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"radialaxis\":{\"visible\":true,\"range\":[0,1]}},\"title\":{\"text\":\"Radar â€” PT vs TFLite\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('eee571da-c4a2-439f-b32d-15c65143fa9e');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import os\nimport time\nimport gdown\nimport numpy as np\nimport pandas as pd\nfrom ultralytics import YOLO\nimport tensorflow as tf\nimport plotly.graph_objects as go\nfrom huggingface_hub import HfApi\n\nDRIVE_ID = '1aK5SY2tKMeSPsUoyloOFHQFy3OPv9zeX'\nMODEL_NAME = 'best.pt'\nHF_TOKEN = \"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\"\nHF_USER = \"JuannMontoya\"\nSPACE_NAME = \"billar-detector-v1\"\n\ngdown.download(f'https://drive.google.com/uc?id={DRIVE_ID}', MODEL_NAME, quiet=True)\n\nmodel = YOLO(MODEL_NAME)\nexport_path = model.export(format='tflite', half=True)\n\ntflite_path = None\nif export_path and os.path.exists(export_path):\n    tflite_path = export_path\nelse:\n    for r,_,fs in os.walk(\".\"):\n        for f in fs:\n            if f.endswith(\".tflite\"):\n                tflite_path = os.path.join(r,f)\n\nsize_pt = os.path.getsize(MODEL_NAME)/(1024*1024)\nsize_tflite = os.path.getsize(tflite_path)/(1024*1024)\n\nN = 5\nimgs = [np.random.randint(0,255,(640,640,3),dtype=np.uint8) for _ in range(N)]\n\npt_times = []\ntflite_times = []\nious = []\n\ndef iou(box1, box2):\n    x1=max(box1[0],box2[0])\n    y1=max(box1[1],box2[1])\n    x2=min(box1[2],box2[2])\n    y2=min(box1[3],box2[3])\n    inter=max(0,x2-x1)*max(0,y2-y1)\n    a1=(box1[2]-box1[0])*(box1[3]-box1[1])\n    a2=(box2[2]-box2[0])*(box2[3]-box2[1])\n    union=a1+a2-inter\n    return inter/union if union>0 else 0\n\ninterpreter = tf.lite.Interpreter(model_path=tflite_path)\ninterpreter.allocate_tensors()\ninp = interpreter.get_input_details()\noutp = interpreter.get_output_details()\n\nfor img in imgs:\n    t0 = time.time()\n    r_pt = model(img)[0]\n    pt_times.append((time.time()-t0)*1000)\n    boxes_pt = r_pt.boxes.xyxy.cpu().numpy() if r_pt.boxes is not None else None\n    img_proc = img.astype(np.float32)\n    if inp[0]['dtype'] == np.uint8:\n        img_proc = (img_proc/255.0*255.0).astype(np.uint8)\n    elif inp[0]['dtype'] == np.float32:\n        img_proc = img_proc.astype(np.float32)\n    img_f = np.expand_dims(img_proc, 0)\n    t1 = time.time()\n    interpreter.set_tensor(inp[0]['index'], img_f)\n    interpreter.invoke()\n    out = interpreter.get_tensor(outp[0]['index'])\n    tflite_times.append((time.time()-t1)*1000)\n    if boxes_pt is not None and len(boxes_pt)>0 and out.shape[-1]>=4:\n        b1 = boxes_pt[0]\n        b2 = out[0][:4]\n        ious.append(iou(b1,b2))\n\navg_pt = sum(pt_times)/len(pt_times)\navg_tflite = sum(tflite_times)/len(tflite_times)\navg_iou = sum(ious)/len(ious) if len(ious)>0 else 0\n\ndf = pd.DataFrame({\n    \"MÃ©trica\":[\"TamaÃ±o (MB)\",\"Inferencia ms\",\"IoU promedio\"],\n    \"PT\":[size_pt, avg_pt, 1.0],\n    \"TFLite\":[size_tflite, avg_tflite, avg_iou]\n})\n\nprint(df.to_string(index=False))\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df[\"MÃ©trica\"], y=df[\"PT\"], name=\"PT\"))\nfig.add_trace(go.Bar(x=df[\"MÃ©trica\"], y=df[\"TFLite\"], name=\"TFLite\"))\nfig.update_layout(title=\"ComparaciÃ³n PT vs TFLite\", barmode='group', yaxis_title=\"Valor\")\nfig.show()\n\nfig_time = go.Figure()\nfig_time.add_trace(go.Bar(x=[\"PT\", \"TFLite\"], y=[avg_pt, avg_tflite]))\nfig_time.update_layout(title=\"Tiempo de Inferencia (ms)\", yaxis_title=\"ms\")\nfig_time.show()\n\nmetrics = [\"TamaÃ±o\", \"Inferencia\", \"IoU\"]\npt_norm = np.array([\n    size_pt / max(size_pt, size_tflite),\n    avg_pt / max(avg_pt, avg_tflite) if max(avg_pt, avg_tflite)>0 else 0.0,\n    1.0\n])\ntflite_norm = np.array([\n    size_tflite / max(size_pt, size_tflite),\n    avg_tflite / max(avg_pt, avg_tflite) if max(avg_pt, avg_tflite)>0 else 0.0,\n    avg_iou\n])\n\nfig_radar = go.Figure()\nfig_radar.add_trace(go.Scatterpolar(r=pt_norm, theta=metrics, fill='toself', name='PT'))\nfig_radar.add_trace(go.Scatterpolar(r=tflite_norm, theta=metrics, fill='toself', name='TFLite'))\nfig_radar.update_layout(title=\"Radar â€” PT vs TFLite\", polar=dict(radialaxis=dict(visible=True, range=[0,1])), showlegend=True)\nfig_radar.show()\n\nkeras_model_path = 'keras_model.h5'\nif os.path.exists(keras_model_path):\n    try:\n        from tensorflow import keras\n        test_dataset = None\n        try:\n            test_dataset = eval(\"test_loader.get_dataset()\")\n        except Exception:\n            test_dataset = None\n        if test_dataset is not None:\n            keras_model = keras.models.load_model(keras_model_path)\n            class TFLiteConverter:\n                def __init__(self, model, test_dataset, model_name='model'):\n                    self.model = model\n                    self.test_dataset = test_dataset\n                    self.model_name = model_name\n                    self.results = {}\n                def representative_dataset_gen(self):\n                    for images, _ in self.test_dataset.unbatch().batch(1).take(100):\n                        yield [tf.cast(images, tf.float32)]\n                def convert_to_tflite_float32(self):\n                    converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n                    converter.inference_input_type = tf.float32\n                    converter.inference_output_type = tf.float32\n                    tflite_model = converter.convert()\n                    model_path = f'{self.model_name}_float32.tflite'\n                    with open(model_path, 'wb') as f:\n                        f.write(tflite_model)\n                    return tflite_model, model_path\n                def convert_to_tflite_float16(self):\n                    converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n                    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n                    converter.target_spec.supported_types = [tf.float16]\n                    converter.inference_input_type = tf.float32\n                    converter.inference_output_type = tf.float32\n                    tflite_model = converter.convert()\n                    model_path = f'{self.model_name}_float16.tflite'\n                    with open(model_path, 'wb') as f:\n                        f.write(tflite_model)\n                    return tflite_model, model_path\n                def convert_to_tflite_dynamic_quant(self):\n                    converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n                    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n                    converter.inference_input_type = tf.float32\n                    converter.inference_output_type = tf.float32\n                    tflite_model = converter.convert()\n                    model_path = f'{self.model_name}_dynamic_quant.tflite'\n                    with open(model_path, 'wb') as f:\n                        f.write(tflite_model)\n                    return tflite_model, model_path\n                def convert_to_tflite_int8(self):\n                    converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n                    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n                    converter.representative_dataset = self.representative_dataset_gen\n                    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n                    converter.inference_input_type = tf.uint8\n                    converter.inference_output_type = tf.uint8\n                    tflite_model = converter.convert()\n                    model_path = f'{self.model_name}_int8.tflite'\n                    with open(model_path, 'wb') as f:\n                        f.write(tflite_model)\n                    return tflite_model, model_path\n                def evaluate_tflite_model(self, model_path, model_type):\n                    interpreter = tf.lite.Interpreter(model_path=model_path)\n                    interpreter.allocate_tensors()\n                    input_details = interpreter.get_input_details()\n                    output_details = interpreter.get_output_details()\n                    input_dtype = input_details[0]['dtype']\n                    output_dtype = output_details[0]['dtype']\n                    model_size = os.path.getsize(model_path) / (1024 * 1024)\n                    num_ops = len(interpreter.get_tensor_details())\n                    correct_predictions = 0\n                    top5_correct = 0\n                    total_samples = 0\n                    inference_times = []\n                    total_loss = 0.0\n                    for images, labels in self.test_dataset:\n                        for i in range(images.shape[0]):\n                            image = images[i:i+1].numpy()\n                            label = labels[i].numpy()\n                            if input_dtype == np.uint8:\n                                image = (image * 255.0).astype(np.uint8)\n                            elif input_dtype == np.float32:\n                                image = image.astype(np.float32)\n                            elif input_dtype == np.float16:\n                                image = image.astype(np.float16)\n                            else:\n                                image = image.astype(np.float32)\n                            start_time = time.perf_counter()\n                            interpreter.set_tensor(input_details[0]['index'], image)\n                            interpreter.invoke()\n                            output = interpreter.get_tensor(output_details[0]['index'])\n                            end_time = time.perf_counter()\n                            inference_times.append((end_time - start_time) * 1000)\n                            if output_dtype == np.uint8:\n                                output = output.astype(np.float32) / 255.0\n                            elif output_dtype == np.float32:\n                                output = output.astype(np.float32)\n                            elif output_dtype == np.float16:\n                                output = output.astype(np.float32)\n                            else:\n                                output = output.astype(np.float32)\n                            probs = output[0]\n                            epsilon = 1e-7\n                            loss = -np.log(np.clip(probs[label], epsilon, 1.0))\n                            total_loss += loss\n                            predicted_label = int(np.argmax(probs))\n                            if predicted_label == int(label):\n                                correct_predictions += 1\n                            top5_predictions = np.argsort(probs)[-5:]\n                            if int(label) in top5_predictions:\n                                top5_correct += 1\n                            total_samples += 1\n                    accuracy = correct_predictions / total_samples if total_samples>0 else 0.0\n                    top5_accuracy = top5_correct / total_samples if total_samples>0 else 0.0\n                    avg_loss = total_loss / total_samples if total_samples>0 else 0.0\n                    avg_inference_time = np.mean(inference_times) if inference_times else 0.0\n                    std_inference_time = np.std(inference_times) if inference_times else 0.0\n                    self.results[model_type] = {\n                        'model_path': model_path,\n                        'model_size_mb': model_size,\n                        'num_ops': num_ops,\n                        'input_dtype': str(input_dtype),\n                        'output_dtype': str(output_dtype),\n                        'accuracy': accuracy,\n                        'top5_accuracy': top5_accuracy,\n                        'loss': avg_loss,\n                        'avg_inference_time_ms': avg_inference_time,\n                        'std_inference_time_ms': std_inference_time,\n                        'total_samples': total_samples\n                    }\n                    return self.results[model_type]\n                def evaluate_keras_model(self):\n                    eval_results = self.model.evaluate(self.test_dataset, verbose=0)\n                    loss = eval_results[0] if len(eval_results)>0 else 0.0\n                    accuracy = eval_results[1] if len(eval_results)>1 else 0.0\n                    top5_accuracy = eval_results[2] if len(eval_results)>2 else 0.0\n                    inference_times = []\n                    total_samples = 0\n                    for images, _ in self.test_dataset:\n                        for i in range(images.shape[0]):\n                            image = images[i:i+1]\n                            start_time = time.perf_counter()\n                            _ = self.model(image, training=False)\n                            end_time = time.perf_counter()\n                            inference_times.append((end_time - start_time) * 1000)\n                            total_samples += 1\n                    avg_inference_time = np.mean(inference_times) if inference_times else 0.0\n                    std_inference_time = np.std(inference_times) if inference_times else 0.0\n                    self.model.save('temp_model.h5')\n                    model_size = os.path.getsize('temp_model.h5') / (1024 * 1024)\n                    os.remove('temp_model.h5')\n                    num_ops = sum([1 for layer in self.model.layers])\n                    self.results['keras_original'] = {\n                        'model_path': 'N/A (Keras)',\n                        'model_size_mb': model_size,\n                        'num_ops': num_ops,\n                        'input_dtype': 'float32',\n                        'output_dtype': 'float32',\n                        'accuracy': accuracy,\n                        'top5_accuracy': top5_accuracy,\n                        'loss': loss,\n                        'avg_inference_time_ms': avg_inference_time,\n                        'std_inference_time_ms': std_inference_time,\n                        'total_samples': total_samples\n                    }\n                    return self.results['keras_original']\n                def convert_all(self):\n                    self.evaluate_keras_model()\n                    _, float32_path = self.convert_to_tflite_float32()\n                    self.evaluate_tflite_model(float32_path, 'float32')\n                    _, float16_path = self.convert_to_tflite_float16()\n                    self.evaluate_tflite_model(float16_path, 'float16')\n                    _, dynamic_path = self.convert_to_tflite_dynamic_quant()\n                    self.evaluate_tflite_model(dynamic_path, 'dynamic_quant')\n                    _, int8_path = self.convert_to_tflite_int8()\n                    self.evaluate_tflite_model(int8_path, 'int8')\n                def print_comparison_table(self):\n                        order = ['keras_original', 'float32', 'float16', 'dynamic_quant', 'int8']\n                        header = f\"{'Tipo':<18} {'TamaÃ±o (MB)':<13} {'Ops':<6} {'In/Out dtype':<20} {'Loss':<10} {'Acc':<10} {'Top-5':<10} {'Tiempo (ms)':<13} {'Desv (ms)':<12}\"\n                        print(header)\n                        for model_type in order:\n                            if model_type in self.results:\n                                r = self.results[model_type]\n                                dtype_str = f\"{r['input_dtype']}/{r['output_dtype']}\"\n                                print(\n                                    f\"{model_type:<18} \"\n                                    f\"{r['model_size_mb']:<13.2f} \"\n                                    f\"{r['num_ops']:<6} \"\n                                    f\"{dtype_str:<20} \"\n                                    f\"{r['loss']:<10.4f} \"\n                                    f\"{r['accuracy']:<10.4f} \"\n                                    f\"{r['top5_accuracy']:<10.4f} \"\n                                    f\"{r['avg_inference_time_ms']:<13.2f} \"\n                                    f\"{r['std_inference_time_ms']:<12.2f}\"\n                                    )\n\n            converter = TFLiteConverter(keras_model, test_dataset, 'my_classification_model')\n            converter.convert_all()\n            converter.print_comparison_table()\n    except Exception as e:\n        print(\"Keras conversion skipped or failed:\", str(e))\nelse:\n    print(\"No Keras model found, skipping Keras->TFLite conversion.\")\n\napi = HfApi(token=HF_TOKEN)\nREPO_ID = f\"{HF_USER}/{SPACE_NAME}\"\napi.create_repo(repo_id=REPO_ID, repo_type=\"space\", space_sdk=\"docker\", exist_ok=True)\nreq_txt = \"fastapi\\nuvicorn[standard]\\npillow\\nnumpy\\nai-edge-litert\\n\"\nwith open(\"requirements.txt\",\"w\") as f:\n    f.write(req_txt)\ndockerfile_content = \"\"\"FROM python:3.10\nRUN useradd -m -u 1000 user\nUSER user\nENV PATH=\"/home/user/.local/bin:$PATH\"\nWORKDIR /app\nCOPY --chown=user ./requirements.txt /app/requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY --chown=user . /app\nEXPOSE 7860\nCMD [\\\"uvicorn\\\", \\\"app:app\\\", \\\"--host\\\", \\\"0.0.0.0\\\", \\\"--port\\\", \\\"7860\\\"]\"\"\"\nwith open(\"Dockerfile\",\"w\") as f:\n    f.write(dockerfile_content)\napp_py = \"\"\"\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nimport base64\nimport numpy as np\nfrom PIL import Image\nimport io\nimport tensorflow as tf\n\napp = FastAPI()\nMODEL_PATH = \"model_for_space.tflite\"\ninterpreter = tf.lite.Interpreter(model_path=MODEL_PATH)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nIS_INT8_MODEL = input_details[0]['dtype'] == np.uint8\n\nclass ImagePayload(BaseModel):\n    image_base64: str\n\n@app.get(\"/\")\ndef home():\n    return {\"status\":\"ok\",\"model_info\":{\"input_shape\":input_details[0]['shape'].tolist(),\"input_dtype\":str(input_details[0]['dtype']),\"output_shape\":output_details[0]['shape'].tolist(),\"output_dtype\":str(output_details[0]['dtype']),\"quantized\":bool(IS_INT8_MODEL)}}\n\ndef preprocess_image(img_bytes, target_size=None):\n    img = Image.open(io.BytesIO(img_bytes))\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    if target_size is None:\n        shape = input_details[0]['shape']\n        if len(shape)>=3:\n            target_size = (shape[1], shape[2])\n        else:\n            target_size = (224,224)\n    img = img.resize(target_size, Image.BILINEAR)\n    img_array = np.array(img, dtype=np.float32) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    if IS_INT8_MODEL:\n        img_array = (img_array*255.0).astype(np.uint8)\n    return img_array\n\ndef postprocess_output(output):\n    if IS_INT8_MODEL:\n        output = output.astype(np.float32)\n    return output[0].tolist()\n\nclass ImagePayloadOut(BaseModel):\n    prediction: list\n    predicted_class: int\n    confidence: float\n\n@app.post(\"/predict\", response_model=dict)\ndef predict(payload: ImagePayload):\n    try:\n        img_bytes = base64.b64decode(payload.image_base64)\n        img_array = preprocess_image(img_bytes)\n        interpreter.set_tensor(input_details[0]['index'], img_array)\n        interpreter.invoke()\n        output = interpreter.get_tensor(output_details[0]['index'])\n        preds = postprocess_output(output)\n        pc = int(np.argmax(preds))\n        conf = float(preds[pc]) if len(preds)>0 else 0.0\n        top5 = sorted([(i,float(p)) for i,p in enumerate(preds)], key=lambda x:x[1], reverse=True)[:5]\n        return {\"prediction\":preds,\"predicted_class\":pc,\"confidence\":conf,\"top_5\":top5}\n    except Exception as e:\n        return {\"error\":str(e),\"status\":\"failed\"}\n\"\"\"\nwith open(\"app.py\",\"w\") as f:\n    f.write(app_py)\nmodel_for_space = tflite_path if tflite_path and os.path.exists(tflite_path) else None\nif model_for_space:\n    api.upload_file(path_or_fileobj=\"requirements.txt\", path_in_repo=\"requirements.txt\", repo_id=REPO_ID, repo_type=\"space\")\n    api.upload_file(path_or_fileobj=\"Dockerfile\", path_in_repo=\"Dockerfile\", repo_id=REPO_ID, repo_type=\"space\")\n    api.upload_file(path_or_fileobj=\"app.py\", path_in_repo=\"app.py\", repo_id=REPO_ID, repo_type=\"space\")\n    api.upload_file(path_or_fileobj=model_for_space, path_in_repo=os.path.basename(model_for_space), repo_id=REPO_ID, repo_type=\"space\")\n    print(\"Space creado/actualizado:\", f\"https://huggingface.co/spaces/{REPO_ID}\")\nelse:\n    print(\"No se subiÃ³ modelo al Space porque no se encontrÃ³ tflite.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T12:48:05.969863Z","iopub.execute_input":"2025-12-12T12:48:05.970443Z","iopub.status.idle":"2025-12-12T12:48:32.053949Z","shell.execute_reply.started":"2025-12-12T12:48:05.970416Z","shell.execute_reply":"2025-12-12T12:48:32.053221Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.236 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon CPU @ 2.00GHz)\nYOLO11n summary (fused): 100 layers, 2,587,417 parameters, 0 gradients, 6.3 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 31, 8400) (5.2 MB)\n\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.18.0 opset 19...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.78...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.4s, saved as 'best.onnx' (10.2 MB)\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.5...\nSaved artifact at 'best_saved_model'. The following endpoints are available:\n\n* Endpoint 'serving_default'\n  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\nOutput Type:\n  TensorSpec(shape=(1, 31, 8400), dtype=tf.float32, name=None)\nCaptures:\n  136215722695888: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215722692816: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n  136215722696848: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136222338355600: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136215903980624: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136222338359056: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214497976272: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n  136214497977424: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214497978000: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214497978960: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214497979536: TensorSpec(shape=(3, 3, 16, 8), dtype=tf.float32, name=None)\n  136214497980496: TensorSpec(shape=(8,), dtype=tf.float32, name=None)\n  136214497977808: TensorSpec(shape=(3, 3, 8, 16), dtype=tf.float32, name=None)\n  136214497978384: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136214497978192: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214497978576: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214497980688: TensorSpec(shape=(1, 1, 48, 64), dtype=tf.float32, name=None)\n  136214497980880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214497980112: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136214497979152: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214497979920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214497981072: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214497981456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214497982032: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214497981840: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214497982800: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n  136214497984144: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136214497981648: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136214497981264: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214497982224: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214497982416: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214497983568: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n  136214497984336: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214497983376: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136214497982992: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  136214801219856: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214801219664: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136214801220240: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214801220816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801220624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801221584: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n  136214801222928: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214801223312: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136214801223120: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214801220048: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136214801222352: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214801223696: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136214801223888: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214801222160: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  136214801220432: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n  136214801224080: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214801221776: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214801224656: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214801224464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214801221008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801221200: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801224848: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136214801223504: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214801225232: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136214801225040: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n  136214801224272: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214801225424: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136214801225808: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214801226384: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801226192: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801227152: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136214801228496: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214801228880: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214801228688: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214801225616: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214801227920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214801229264: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214801229456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214801227728: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214801226000: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136214801229648: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214801227344: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214801230224: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136214801230032: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214801226576: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801226768: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801230416: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136214801229072: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214801230608: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  136214801230800: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214801231184: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n  136214801230992: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214801231376: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136214801231568: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214801232144: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n  136214801229840: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214801234064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  136214801231952: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214801233104: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136214801234448: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214801235024: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n  136214801233680: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214801234640: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  136214801235216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214801232720: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  136214801233872: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214801234832: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n  136214801234256: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214526951888: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526952272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801233296: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n  136214801232336: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214801235408: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n  136214801231760: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214801235600: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214801235792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526953232: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136214526953424: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214526953040: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n  136214526952464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526954000: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526953808: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526954768: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n  136214526956112: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  136214526953616: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  136214526951696: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214526954192: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526954384: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526956304: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n  136214526956496: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526955536: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136214526954960: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214526955344: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526958224: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136214526958416: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214526958992: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526959760: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526962064: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n  136214526959568: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  136214526962448: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n  136214526962256: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526960144: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526960336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526963408: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  136214526963600: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214526964368: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  136214526964560: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  136214526963216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214526963792: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136214526965136: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214526965712: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526966480: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526967632: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136214526966672: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800238160: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214800237968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800239120: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214800240080: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800240272: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214800238352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800238544: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214526967248: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136214800239888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526966288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800239504: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  136214800240464: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214526966864: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214526967056: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  136214800240848: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  136214800239312: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214800241040: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n  136214526963984: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n  136214526957456: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136214800239696: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  136214526963024: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  136214526957072: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800241424: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n  136214526964752: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  136214526957840: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214800241232: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526964176: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526957264: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800242576: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136214800240656: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n  136214526966096: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136214526961488: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n  136214526959376: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n  136214526956688: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214800241808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800238736: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526965328: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526964944: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526958608: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526956880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800242960: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214800238928: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214526967440: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214526962640: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214526960912: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214526957648: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  136214800242000: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800241616: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800237008: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526962832: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526960720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526958032: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800243152: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136214800242192: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214800237584: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136214526965904: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214526959952: TensorSpec(shape=(1, 1, 64, 27), dtype=tf.float32, name=None)\n  136214526959184: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  136214800242384: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800243344: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136214526965520: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214800237776: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136214526958800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  136214526961296: TensorSpec(shape=(27,), dtype=tf.float32, name=None)\n  136214800243920: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n  136214800245648: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136214800245072: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136214800244304: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136214800245840: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  136214800246224: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n  136214800242768: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1765543702.495553     136 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1765543702.495738     136 single_machine.cc:361] Starting new session\nW0000 00:00:1765543703.306711     136 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1765543703.306742     136 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1765543703.985215     136 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1765543703.985378     136 single_machine.cc:361] Starting new session\nW0000 00:00:1765543704.728089     136 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1765543704.728121     136 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 15.2s, saved as 'best_saved_model' (25.6 MB)\n\n\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'best_saved_model/best_float16.tflite' (5.1 MB)\n\nExport complete (15.6s)\nResults saved to \u001b[1m/kaggle/working\u001b[0m\nPredict:         yolo predict task=detect model=best_saved_model/best_float16.tflite imgsz=640 half \nValidate:        yolo val task=detect model=best_saved_model/best_float16.tflite imgsz=640 data=/kaggle/working/PDI_Project-1/data.yaml half \nVisualize:       https://netron.app\n\n0: 640x640 (no detections), 102.4ms\nSpeed: 3.3ms preprocess, 102.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 117.7ms\nSpeed: 3.8ms preprocess, 117.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 99.4ms\nSpeed: 2.6ms preprocess, 99.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 103.4ms\nSpeed: 2.6ms preprocess, 103.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n\n0: 640x640 (no detections), 102.4ms\nSpeed: 2.5ms preprocess, 102.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n      MÃ©trica         PT     TFLite\n  TamaÃ±o (MB)   5.245807   5.128462\nInferencia ms 119.105911 129.246569\n IoU promedio   1.000000   0.000000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ad1c69ae-2e37-4320-a7b9-cba7f8ca3af9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ad1c69ae-2e37-4320-a7b9-cba7f8ca3af9\")) {                    Plotly.newPlot(                        \"ad1c69ae-2e37-4320-a7b9-cba7f8ca3af9\",                        [{\"name\":\"PT\",\"x\":[\"TamaÃ±o (MB)\",\"Inferencia ms\",\"IoU promedio\"],\"y\":[5.245806694030762,119.10591125488281,1.0],\"type\":\"bar\"},{\"name\":\"TFLite\",\"x\":[\"TamaÃ±o (MB)\",\"Inferencia ms\",\"IoU promedio\"],\"y\":[5.128461837768555,129.24656867980957,0.0],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"ComparaciÃ³n PT vs TFLite\"},\"barmode\":\"group\",\"yaxis\":{\"title\":{\"text\":\"Valor\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('ad1c69ae-2e37-4320-a7b9-cba7f8ca3af9');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"80b6fec9-680f-4d04-a1b5-40bec2bd0cfe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"80b6fec9-680f-4d04-a1b5-40bec2bd0cfe\")) {                    Plotly.newPlot(                        \"80b6fec9-680f-4d04-a1b5-40bec2bd0cfe\",                        [{\"x\":[\"PT\",\"TFLite\"],\"y\":[119.10591125488281,129.24656867980957],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Tiempo de Inferencia (ms)\"},\"yaxis\":{\"title\":{\"text\":\"ms\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('80b6fec9-680f-4d04-a1b5-40bec2bd0cfe');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c40f63cd-4d06-4d0a-8490-039530c743d9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c40f63cd-4d06-4d0a-8490-039530c743d9\")) {                    Plotly.newPlot(                        \"c40f63cd-4d06-4d0a-8490-039530c743d9\",                        [{\"fill\":\"toself\",\"name\":\"PT\",\"r\":[1.0,0.9215402193767416,1.0],\"theta\":[\"TamaÃ±o\",\"Inferencia\",\"IoU\"],\"type\":\"scatterpolar\"},{\"fill\":\"toself\",\"name\":\"TFLite\",\"r\":[0.9776307319147436,1.0,0.0],\"theta\":[\"TamaÃ±o\",\"Inferencia\",\"IoU\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"radialaxis\":{\"visible\":true,\"range\":[0,1]}},\"title\":{\"text\":\"Radar â€” PT vs TFLite\"},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('c40f63cd-4d06-4d0a-8490-039530c743d9');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"name":"stdout","text":"No Keras model found, skipping Keras->TFLite conversion.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a8799242a64e52b3d6d127b87b810d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f230d693b441e486b3715ee822af5c"}},"metadata":{}},{"name":"stdout","text":"Space creado/actualizado: https://huggingface.co/spaces/JuannMontoya/billar-detector-v1\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"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","metadata":{}},{"cell_type":"code","source":"!pip install huggingface_hub -q\n\nimport os\nfrom huggingface_hub import HfApi\n\n# ================================\n# CONFIG\n# ================================\nHF_TOKEN = \"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\"\nUSER = \"JuannMontoya\"\nSPACE = \"billar-detector-v1\"\nMODEL_PT = \"best.pt\"\n\nREPO_ID = f\"{USER}/{SPACE}\"\n\napi = HfApi(token=HF_TOKEN)\n\nprint(f\"Creando Space: https://huggingface.co/spaces/{REPO_ID}\")\n\n\n# ================================\n# 1. REQUIREMENTS.TXT (VERSIONES COMPATIBLES)\n# ================================\nreq = \"\"\"\nultralytics\nopencv-python-headless\ntensorflow-cpu\nnumpy\ngradio==4.19.0\nhuggingface_hub==0.23.0\n\"\"\"\nopen(\"requirements.txt\", \"w\").write(req)\n\n\n# ================================\n# 2. DOCKERFILE CORREGIDO\n# ================================\ndocker = \"\"\"\nFROM python:3.9-slim\n\nRUN apt-get update && apt-get install -y \\\\\n    ffmpeg \\\\\n    libsm6 \\\\\n    libxext6 \\\\\n    libgl1 \\\\\n    libglib2.0-0 \\\\\n    && rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD [\"python\", \"app.py\"]\n\"\"\"\nopen(\"Dockerfile\", \"w\").write(docker)\n\n\n# ================================\n# 3. APP.PY\n# ================================\napp = \"\"\"\nimport gradio as gr\nimport cv2\nfrom ultralytics import YOLO\n\nmodel = YOLO(\"best.pt\")\n\ndef infer(video):\n    cap = cv2.VideoCapture(video)\n\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    w   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    h   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    out = cv2.VideoWriter(\"out.mp4\",\n                          cv2.VideoWriter_fourcc(*'mp4v'),\n                          fps,\n                          (w, h))\n\n    while True:\n        ok, frame = cap.read()\n        if not ok:\n            break\n\n        r = model(frame)[0]\n\n        for box in r.boxes.xyxy:\n            x1,y1,x2,y2 = map(int, box[:4])\n            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n    return \"out.mp4\"\n\nui = gr.Interface(\n    fn=infer,\n    inputs=gr.Video(),\n    outputs=gr.Video(),\n    title=\"Detector de Billar YOLO\"\n)\n\nif __name__ == \"__main__\":\n    ui.launch(server_name=\"0.0.0.0\", server_port=7860)\n\"\"\"\nopen(\"app.py\",\"w\").write(app)\n\n\n# ================================\n# 4. CREAR SPACE\n# ================================\napi.create_repo(\n    repo_id=REPO_ID,\n    repo_type=\"space\",\n    space_sdk=\"docker\",\n    exist_ok=True\n)\n\n# ================================\n# 5. SUBIR ARCHIVOS\n# ================================\nfiles = [\"Dockerfile\", \"requirements.txt\", \"app.py\", MODEL_PT]\n\nfor f in files:\n    api.upload_file(\n        repo_id=REPO_ID,\n        repo_type=\"space\",\n        path_in_repo=f,\n        path_or_fileobj=f\n    )\n    print(f\"âœ” Subido: {f}\")\n\nprint(\"\\nðŸŽ‰ DEPLOY LISTO\")\nprint(f\"https://huggingface.co/spaces/{REPO_ID}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:05:47.639655Z","iopub.execute_input":"2025-12-12T13:05:47.640207Z","iopub.status.idle":"2025-12-12T13:05:54.431916Z","shell.execute_reply.started":"2025-12-12T13:05:47.640178Z","shell.execute_reply":"2025-12-12T13:05:54.431157Z"}},"outputs":[{"name":"stdout","text":"Creando Space: https://huggingface.co/spaces/JuannMontoya/billar-detector-v1\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\nWARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"âœ” Subido: Dockerfile\nâœ” Subido: requirements.txt\nâœ” Subido: app.py\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b7362c3314b4f6699c61ddcb10d6fc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599da781402e4179ac26a12d11afecfb"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\nWARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"âœ” Subido: best.pt\n\nðŸŽ‰ DEPLOY LISTO\nhttps://huggingface.co/spaces/JuannMontoya/billar-detector-v1\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"!pip install gradio_client","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:12:02.233723Z","iopub.execute_input":"2025-12-12T13:12:02.234448Z","iopub.status.idle":"2025-12-12T13:12:05.463984Z","shell.execute_reply.started":"2025-12-12T13:12:02.234417Z","shell.execute_reply":"2025-12-12T13:12:05.463018Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gradio_client in /usr/local/lib/python3.11/dist-packages (1.11.0)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio_client) (2025.10.0)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio_client) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from gradio_client) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio_client) (25.0)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio_client) (4.15.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio_client) (15.0.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio_client) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio_client) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio_client) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio_client) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio_client) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (3.20.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (1.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.24.1->gradio_client) (1.3.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (2.5.0)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!pip install huggingface_hub -q\n\nimport os\nfrom huggingface_hub import HfApi\n\n# ================================\n# CONFIG\n# ================================\nHF_TOKEN = \"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\"   # â† REEMPLAZA ESTO\nUSER = \"JuannMontoya\"\nSPACE = \"billar-detector-v1\"     # â† EL MISMO QUE TÃš USAS\nMODEL_ONNX = \"/kaggle/working/best.onnx\"\n\nREPO_ID = f\"{USER}/{SPACE}\"\n\napi = HfApi(token=HF_TOKEN)\n\nprint(f\"Actualizando Space: https://huggingface.co/spaces/{REPO_ID}\")\n\n\n# ================================\n# 1. REQUIREMENTS\n# ================================\nreq = \"\"\"\nonnxruntime\nopencv-python-headless\nnumpy\ngradio==4.19.0\nhuggingface_hub==0.23.0\n\"\"\"\nopen(\"requirements.txt\", \"w\").write(req)\n\n\n\n# ================================\n# 2. DOCKERFILE\n# ================================\ndocker = \"\"\"\nFROM python:3.9-slim\n\nRUN apt-get update && apt-get install -y \\\\\n    ffmpeg \\\\\n    libsm6 \\\\\n    libxext6 \\\\\n    libgl1 \\\\\n    libglib2.0-0 \\\\\n    && rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD [\"python\", \"app.py\"]\n\"\"\"\nopen(\"Dockerfile\", \"w\").write(docker)\n\n\n\n# ================================\n# 3. APP.PY (ONNX + EVENTOS BOLA/TRONERA)\n# ================================\napp = r'''\nimport gradio as gr\nimport cv2\nimport numpy as np\nimport onnxruntime as ort\n\nsession = ort.InferenceSession(\"best.onnx\", providers=[\"CPUExecutionProvider\"])\ninput_name = session.get_inputs()[0].name\nIMG_SIZE = session.get_inputs()[0].shape[2]\n\nnames = {\n  0:'0', 1:'1', 2:'10', 3:'11', 4:'12', 5:'13', 6:'14', 7:'15',\n  8:'2', 9:'3', 10:'4', 11:'5', 12:'6', 13:'7', 14:'8', 15:'9',\n  16:'94',\n  17:'BottomLeft', 18:'BottomRight',\n  21:'MediumLeft', 22:'MediumRight',\n  25:'TopLeft', 26:'TopRight'\n}\n\ntroneras = [\n    \"BottomLeft\",\"BottomRight\",\n    \"MediumLeft\",\"MediumRight\",\n    \"TopLeft\",\"TopRight\"\n]\n\ndef preprocess(image):\n    img = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32) / 255.\n    img = np.transpose(img, (2,0,1))\n    return img[np.newaxis, :, :, :]\n\ndef postprocess(outputs, conf_th=0.4):\n    preds = outputs[0]\n    boxes = []\n    for d in preds:\n        x1,y1,x2,y2,score,cls = d[:6]\n        if score < conf_th:\n            continue\n        boxes.append({\n            \"cls\": int(cls),\n            \"label\": names[int(cls)],\n            \"score\": float(score),\n            \"box\": [float(x1), float(y1), float(x2), float(y2)]\n        })\n    return boxes\n\ndef inside(bola, tronera):\n    bx1,by1,bx2,by2 = bola[\"box\"]\n    tx1,ty1,tx2,ty2 = tronera[\"box\"]\n    cx = (bx1 + bx2)/2\n    cy = (by1 + by2)/2\n    return (tx1<=cx<=tx2) and (ty1<=cy<=ty2)\n\ndef infer(video):\n\n    cap = cv2.VideoCapture(video)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    w   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    h   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    out = cv2.VideoWriter(\"out.mp4\",\n                          cv2.VideoWriter_fourcc(*'mp4v'),\n                          fps,\n                          (w, h))\n\n    while True:\n        ok, frame = cap.read()\n        if not ok:\n            break\n\n        blob = preprocess(frame)\n        outputs = session.run(None, {input_name: blob})\n        dets = postprocess(outputs, conf_th=0.45)\n\n        bolas = [d for d in dets if d[\"label\"].isdigit()]\n        trons = [d for d in dets if d[\"label\"] in troneras]\n\n        for d in dets:\n            x1,y1,x2,y2 = map(int, d[\"box\"])\n            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n            cv2.putText(frame, d[\"label\"], (x1,y1-5),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n\n        # EVENTOS EN PANTALLA\n        y_offset = 40\n        for bola in bolas:\n            for tr in trons:\n                if inside(bola, tr):\n                    msg = f\"Bola {bola['label']} entrÃ³ en {tr['label']}\"\n                    cv2.putText(frame, msg, (20, y_offset),\n                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,255), 2)\n                    y_offset += 30\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n    return \"out.mp4\"\n\nui = gr.Interface(\n    fn=infer,\n    inputs=gr.Video(),\n    outputs=gr.Video(),\n    title=\"Detector de Billar ONNX (Bola â†’ Tronera)\"\n)\n\nif __name__ == \"__main__\":\n    ui.launch(server_name=\"0.0.0.0\", server_port=7860)\n'''\nopen(\"app.py\",\"w\").write(app)\n\n\n\n# ================================\n# 4. CREAR/ACTUALIZAR SPACE\n# ================================\napi.create_repo(\n    repo_id=REPO_ID,\n    repo_type=\"space\",\n    space_sdk=\"docker\",\n    exist_ok=True\n)\n\n\n\n# ================================\n# 5. SUBIR ARCHIVOS\n# ================================\nos.system(f\"cp {MODEL_ONNX} best.onnx\")\n\nfiles = [\"Dockerfile\", \"requirements.txt\", \"app.py\", \"best.onnx\"]\n\nfor f in files:\n    api.upload_file(\n        repo_id=REPO_ID,\n        repo_type=\"space\",\n        path_in_repo=f,\n        path_or_fileobj=f\n    )\n    print(f\"âœ” Subido: {f}\")\n\nprint(\"\\nðŸŽ‰ DEPLOY LISTO\")\nprint(f\"https://huggingface.co/spaces/{REPO_ID}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T13:24:09.929743Z","iopub.execute_input":"2025-12-12T13:24:09.930492Z","iopub.status.idle":"2025-12-12T13:24:15.309251Z","shell.execute_reply.started":"2025-12-12T13:24:09.930460Z","shell.execute_reply":"2025-12-12T13:24:15.308637Z"}},"outputs":[{"name":"stdout","text":"Actualizando Space: https://huggingface.co/spaces/JuannMontoya/billar-detector-v1\n","output_type":"stream"},{"name":"stderr","text":"cp: '/kaggle/working/best.onnx' and 'best.onnx' are the same file\nNo files have been modified since last commit. Skipping to prevent empty commit.\nWARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nWARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"âœ” Subido: Dockerfile\nâœ” Subido: requirements.txt\nâœ” Subido: app.py\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8b75f82108944bab70440a043172448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bafbe7c33564f98a11976ac86a10a4d"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\nWARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"âœ” Subido: best.onnx\n\nðŸŽ‰ DEPLOY LISTO\nhttps://huggingface.co/spaces/JuannMontoya/billar-detector-v1\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"#API\n\n# from gradio_client import Client\n\n# client = Client(\"https://juannmontoya-billar-detector-v1.hf.space/\")\n\n# result = client.predict(\n#     {\n#         \"video\": \"https://raw.githubusercontent.com/usuario/repositorio/main/video.mp4\",\n#         \"subtitles\": None\n#     },\n#     api_name=\"/predict\"\n# )\n\n# print(result)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}